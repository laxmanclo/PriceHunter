#!/usr/bin/env python3
"""
Real scraper test against actual websites.
Tests the enhanced PriceHunter system with live data.
"""

import asyncio
import json
import time
from datetime import datetime
from typing import List

from src.core.price_fetcher import PriceFetcher, SearchRequest


async def test_us_real_scrapers():
    """Test US market with real scrapers."""
    print("\nğŸ‡ºğŸ‡¸ Testing US Market - REAL SCRAPERS")
    print("=" * 60)
    
    fetcher = PriceFetcher()
    
    # Test the exact query that was failing before
    request = SearchRequest(
        country="US", 
        query="iPhone 16 Pro, 128GB",
        max_results=10,
        timeout=30
    )
    
    print(f"ğŸ” Searching for: '{request.query}'")
    print(f"ğŸ“ Country: {request.country}")
    print(f"â±ï¸  Timeout: {request.timeout}s")
    print(f"ğŸ“Š Max results: {request.max_results}")
    print()
    
    start_time = time.time()
    try:
        response = await fetcher.search(request)
        end_time = time.time()
        
        print(f"âœ… Search completed in {end_time - start_time:.2f} seconds")
        print(f"ğŸ“Š Found {response.total_results} results from {len(response.sources_used)} sources")
        print(f"ğŸª Sources used: {', '.join(response.sources_used)}")
        print()
        
        if response.results:
            print("ğŸ† Top Results:")
            for i, result in enumerate(response.results[:5], 1):
                print(f"{i}. {result['productName'][:60]}...")
                print(f"   ğŸ’° ${result['price']} {result['currency']} - {result['seller']}")
                if result.get('rating'):
                    print(f"   â­ {result['rating']} ({result.get('reviewsCount', 0)} reviews)")
                print(f"   ğŸ”— {result['link'][:70]}...")
                print(f"   ğŸ“ˆ Similarity: {result.get('similarityScore', 0):.3f}")
                print()
        else:
            print("âŒ No results found")
            print("ğŸ” This might be due to:")
            print("   - Anti-bot protection")
            print("   - Rate limiting")
            print("   - Changed website structure")
            print("   - Network issues")
        
        return response
        
    except Exception as e:
        end_time = time.time()
        print(f"âŒ Error after {end_time - start_time:.2f} seconds: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_indian_real_scrapers():
    """Test Indian market with real scrapers."""
    print("\nğŸ‡®ğŸ‡³ Testing Indian Market - REAL SCRAPERS")
    print("=" * 60)
    
    fetcher = PriceFetcher()
    
    request = SearchRequest(
        country="IN", 
        query="iPhone 16 Pro, 128GB",
        max_results=10,
        timeout=30
    )
    
    print(f"ğŸ” Searching for: '{request.query}'")
    print(f"ğŸ“ Country: {request.country}")
    print(f"â±ï¸  Timeout: {request.timeout}s")
    print(f"ğŸ“Š Max results: {request.max_results}")
    print()
    
    start_time = time.time()
    try:
        response = await fetcher.search(request)
        end_time = time.time()
        
        print(f"âœ… Search completed in {end_time - start_time:.2f} seconds")
        print(f"ğŸ“Š Found {response.total_results} results from {len(response.sources_used)} sources")
        print(f"ğŸª Sources used: {', '.join(response.sources_used)}")
        print()
        
        if response.results:
            print("ğŸ† Top Results:")
            for i, result in enumerate(response.results[:5], 1):
                print(f"{i}. {result['productName'][:60]}...")
                print(f"   ğŸ’° â‚¹{result['price']} {result['currency']} - {result['seller']}")
                if result.get('rating'):
                    print(f"   â­ {result['rating']} ({result.get('reviewsCount', 0)} reviews)")
                print(f"   ğŸ”— {result['link'][:70]}...")
                print(f"   ğŸ“ˆ Similarity: {result.get('similarityScore', 0):.3f}")
                print()
        else:
            print("âŒ No results found")
            print("ğŸ” This might be due to:")
            print("   - Anti-bot protection")
            print("   - Rate limiting") 
            print("   - Changed website structure")
            print("   - Network issues")
        
        return response
        
    except Exception as e:
        end_time = time.time()
        print(f"âŒ Error after {end_time - start_time:.2f} seconds: {e}")
        import traceback
        traceback.print_exc()
        return None


async def test_different_queries():
    """Test with different product queries."""
    print("\nğŸ” Testing Different Product Queries")
    print("=" * 60)
    
    test_queries = [
        ("US", "MacBook Pro M3"),
        ("US", "Samsung Galaxy S24"),
        ("IN", "OnePlus 12"),
        ("IN", "MacBook Air M2"),
    ]
    
    fetcher = PriceFetcher()
    
    for country, query in test_queries:
        print(f"\nğŸ” Testing: '{query}' in {country}")
        print("-" * 40)
        
        request = SearchRequest(
            country=country,
            query=query,
            max_results=3,
            timeout=20
        )
        
        try:
            start_time = time.time()
            response = await fetcher.search(request)
            end_time = time.time()
            
            print(f"â±ï¸  {end_time - start_time:.1f}s | ğŸ“Š {response.total_results} results | ğŸª {len(response.sources_used)} sources")
            
            if response.results:
                result = response.results[0]  # Show top result
                print(f"ğŸ† {result['productName'][:50]}... - ${result['price']} from {result['seller']}")
            else:
                print("âŒ No results")
                
        except Exception as e:
            print(f"âŒ Error: {str(e)[:50]}...")
        
        # Small delay between requests
        await asyncio.sleep(1)


async def main():
    """Run all real scraper tests."""
    print("ğŸš€ PriceHunter Real Scraper Test")
    print("Testing enhanced system against actual websites")
    print("=" * 70)
    
    # Test 1: US Market (the original failing query)
    us_response = await test_us_real_scrapers()
    
    # Small delay between tests
    await asyncio.sleep(2)
    
    # Test 2: Indian Market
    indian_response = await test_indian_real_scrapers()
    
    # Small delay between tests
    await asyncio.sleep(2)
    
    # Test 3: Different queries
    await test_different_queries()
    
    # Summary
    print("\nğŸ“ˆ Test Summary")
    print("=" * 50)
    
    if us_response:
        print(f"ğŸ‡ºğŸ‡¸ US Market: âœ… {us_response.total_results} results in {us_response.search_time:.2f}s")
    else:
        print("ğŸ‡ºğŸ‡¸ US Market: âŒ Failed")
    
    if indian_response:
        print(f"ğŸ‡®ğŸ‡³ Indian Market: âœ… {indian_response.total_results} results in {indian_response.search_time:.2f}s")
    else:
        print("ğŸ‡®ğŸ‡³ Indian Market: âŒ Failed")
    
    # Export results if we have any
    if us_response or indian_response:
        print(f"\nğŸ’¾ Exporting results...")
        
        export_data = {
            "timestamp": datetime.now().isoformat(),
            "test_type": "real_scrapers",
            "us_market": {
                "success": us_response is not None,
                "results": us_response.total_results if us_response else 0,
                "search_time": us_response.search_time if us_response else 0,
                "sources": us_response.sources_used if us_response else [],
                "top_result": us_response.results[0] if us_response and us_response.results else None
            },
            "indian_market": {
                "success": indian_response is not None,
                "results": indian_response.total_results if indian_response else 0,
                "search_time": indian_response.search_time if indian_response else 0,
                "sources": indian_response.sources_used if indian_response else [],
                "top_result": indian_response.results[0] if indian_response and indian_response.results else None
            }
        }
        
        with open("real_scraper_test_results.json", "w") as f:
            json.dump(export_data, f, indent=2)
        
        print("âœ… Results exported to real_scraper_test_results.json")
    
    print(f"\nğŸ¯ Test completed at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    asyncio.run(main())
